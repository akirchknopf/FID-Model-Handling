{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Training visual modality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from time import time, gmtime, strftime\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from utils.textUtils.textpreprocessing import FakeDetectionDataTest, FakeDetectionDataTrainVal\n",
    "\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "from final_models import create_image_resnet101v2_model\n",
    "\n",
    "from utils.callbacks.MyCallbacks import MyCallbacks\n",
    "\n",
    "from utils.datagenUtils.DataSeqThreeModels import DataSequenceThreeModels\n",
    "\n",
    "from utils.telegramUtils.telegram_bot import telegram_send_message\n",
    "\n",
    "from utils.textUtils.textpreprocessing import FakeDetectionDataTrainVal, FakeDetectionDataTest\n",
    "\n",
    "from utils.callbacks.callbackUtils import plotTimesPerEpoch\n",
    "\n",
    "from utils.fileDirUtils.fileDirUtils import createDirIfNotExists\n",
    "\n",
    "from utils.models.modelUtils import checkDataframe, loadMeanFromFile, calAccImageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Batch Size: 128, Epochs: 10, Optimizer: Adam, Learning Rate; 1e-05, Beta_1: 0.9, Beta_2: 0.999, Epsilon: 1e-08\n"
     ]
    }
   ],
   "source": [
    "#Verbose settings:\n",
    "verbose = False\n",
    "TF_VERBOSE = 1 # 1 = Progress bar 2 = one line per epoch only!\n",
    "TF_DETERMINISTIC_OPS = 1 # Makes everything also on GPU deterministic\n",
    "\n",
    "# Classes:\n",
    "NUM_CLASS = 2  # FAKE | NO FAKE\n",
    "\n",
    "# Hyperparameters\n",
    "GLOBAL_BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "# Optimizer parameters:\n",
    "# Adam\n",
    "LEARNING_RATE = 1e-5\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "#optimizers:\n",
    "\n",
    "optimizer = Adam(LEARNING_RATE)\n",
    "\n",
    "# Image Model  Parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_DEPTH = 3\n",
    "IMG_SIZES = (IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "# Custom telegram send text \n",
    "CUSTOM_TEXT = f'Batch Size: {GLOBAL_BATCH_SIZE}, Epochs: {EPOCHS}, Optimizer: Adam, Learning Rate; {LEARNING_RATE}, Beta_1: {BETA_1}, Beta_2: {BETA_2}, Epsilon: {EPSILON}'\n",
    "\n",
    "\n",
    "telegram_send_message(f'-----------------START-----------------')\n",
    "print('START')\n",
    "print(CUSTOM_TEXT)\n",
    "telegram_send_message(CUSTOM_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "root = '/home/armin/repos/fkd-model-handling/'\n",
    "\n",
    "pathToImagesTrain = '/home/armin/repos/FKD-Dataset/006_Bilder_Resized/train/' \n",
    "pathToCSVWithFileNamesAndLabelsTrain = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/train_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesVal = '/home/armin/repos/FKD-Dataset/006_Bilder_Resized/val/' \n",
    "pathToCSVWithFileNamesAndLabelsVal = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/val_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesTest = '/home/armin/repos/FKD-Dataset/006_Bilder_Resized/test/' \n",
    "pathToCSVWithFileNamesAndLabelsTest = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/test_text_image_meta_label.csv'\n",
    "\n",
    "pathToMeans = '/home/armin/repos/FKD-Dataset/010_configs/means_resized.txt'\n",
    "\n",
    "checkpointDir = '/home/armin/repos/FKD-Dataset/011_checkpoints'\n",
    "\n",
    "bert_model_dir = os.path.join(root, 'multi_cased_L-12_H-768_A-12')\n",
    "bert_ckpt_file = os.path.join(bert_model_dir, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_model_dir, \"bert_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other ettings\n",
    "\n",
    "# Time settings:\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "#Checkpoint settings:\n",
    "checkpoint_name = \"ResNet101V2\"\n",
    "\n",
    "checkpointDir = os.path.join(checkpointDir, (checkpoint_name + '_' + current_time))\n",
    "\n",
    "fileName=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filePath = os.path.join(checkpointDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Needed to remove 110 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 74 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 92 elements to make it matching from dataframe\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "df_train = pd.read_csv(pathToCSVWithFileNamesAndLabelsTrain, header=0, sep='\\t')\n",
    "df_test = pd.read_csv(pathToCSVWithFileNamesAndLabelsTest, header=0, sep='\\t')\n",
    "df_val = pd.read_csv(pathToCSVWithFileNamesAndLabelsVal, header=0, sep='\\t')\n",
    "\n",
    "df_train['2_way_label'] = df_train['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_test['2_way_label'] = df_test['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_val['2_way_label'] = df_val['2_way_label'].apply(lambda x: np.array(x))\n",
    "\n",
    "# df_train = df_train[:512]\n",
    "# df_test = df_test[:512]\n",
    "# df_val = df_val[:512]\n",
    "\n",
    "df_train = checkDataframe(df_train, GLOBAL_BATCH_SIZE)\n",
    "df_test = checkDataframe(df_test, GLOBAL_BATCH_SIZE)       \n",
    "df_val = checkDataframe(df_val, GLOBAL_BATCH_SIZE)   \n",
    "\n",
    "STEP_SIZE_TRAIN = len(df_train) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_TEST = len(df_test) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_VAL = len(df_val) // GLOBAL_BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/armin/repos/FKD-Dataset/011_checkpoints/ResNet101V2_2020-07-10_16:43/tensorboard does not exist, creating it instead!\n"
     ]
    }
   ],
   "source": [
    "# Callback Handling:\n",
    "tensorboardDir = os.path.join(checkpointDir, 'tensorboard')\n",
    "\n",
    "createDirIfNotExists(tensorboardDir)\n",
    "createDirIfNotExists(checkpointDir)\n",
    "\n",
    "\n",
    "callbacks_list = MyCallbacks(tensorboardDir, filePath, earlyStopping=True).createCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansOfDataset = loadMeanFromFile(pathToMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560512it [02:13, 4207.81it/s]\n",
      "58880it [00:14, 4168.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58880it [00:14, 4197.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 512\n"
     ]
    }
   ],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_model_dir, \"vocab.txt\"))\n",
    "\n",
    "all_text_data = FakeDetectionDataTrainVal(df_train, df_val, tokenizer, [0,1])\n",
    "\n",
    "max_seq_len = all_text_data.max_seq_len\n",
    "\n",
    "all_text_test = FakeDetectionDataTest(df_test, tokenizer, [0,1], max_seq_len)\n",
    "\n",
    "train_x = all_text_data.train_x\n",
    "val_x = all_text_data.val_x\n",
    "test_x = all_text_test.test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = DataSequenceThreeModels(df_train, pathToImagesTrain, train_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "test_seq = DataSequenceThreeModels(df_test, pathToImagesTest, test_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "val_seq = DataSequenceThreeModels(df_val, pathToImagesVal,  val_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 346 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 346 all-reduces with algorithm = nccl, num_packs = 1\n",
      "4379/4379 [==============================] - ETA: 0s - accuracy: 0.7429 - loss: 0.5022\n",
      "Epoch 00001: val_loss improved from inf to 0.46859, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/ResNet101V2_2020-07-10_16:43/weights-improvement-01-0.77.hdf5\n",
      "4379/4379 [==============================] - 3666s 837ms/step - accuracy: 0.7429 - loss: 0.5022 - val_accuracy: 0.7667 - val_loss: 0.4686 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "4379/4379 [==============================] - ETA: 0s - accuracy: 0.8192 - loss: 0.3849\n",
      "Epoch 00002: val_loss improved from 0.46859 to 0.46116, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/ResNet101V2_2020-07-10_16:43/weights-improvement-02-0.77.hdf5\n",
      "4379/4379 [==============================] - 4067s 929ms/step - accuracy: 0.8192 - loss: 0.3849 - val_accuracy: 0.7749 - val_loss: 0.4612 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "4379/4379 [==============================] - ETA: 0s - accuracy: 0.8972 - loss: 0.2443\n",
      "Epoch 00003: val_loss did not improve from 0.46116\n",
      "4379/4379 [==============================] - 2817s 643ms/step - accuracy: 0.8972 - loss: 0.2443 - val_accuracy: 0.7677 - val_loss: 0.5384 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "4379/4379 [==============================] - ETA: 0s - accuracy: 0.9662 - loss: 0.0961\n",
      "Epoch 00004: val_loss did not improve from 0.46116\n",
      "4379/4379 [==============================] - 2860s 653ms/step - accuracy: 0.9662 - loss: 0.0961 - val_accuracy: 0.7554 - val_loss: 0.8041 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "4379/4379 [==============================] - ETA: 0s - accuracy: 0.9875 - loss: 0.0419\n",
      "Epoch 00005: val_loss did not improve from 0.46116\n",
      "Restoring model weights from the end of the best epoch.\n",
      "4379/4379 [==============================] - 3406s 778ms/step - accuracy: 0.9875 - loss: 0.0419 - val_accuracy: 0.7606 - val_loss: 1.0620 - lr: 1.0000e-05\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    model = create_image_resnet101v2_model(NUM_CLASS)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_seq,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        epochs=EPOCHS, \n",
    "                        validation_data=val_seq,\n",
    "                        validation_steps=STEP_SIZE_VAL,\n",
    "                        callbacks=callbacks_list,\n",
    "                        verbose = TF_VERBOSE\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 281.79978593587873 minutes to train everything\n"
     ]
    }
   ],
   "source": [
    "end = time()\n",
    "timeProceed = (end - start) / 60\n",
    "print(f'It took {timeProceed} minutes to train everything' )\n",
    "telegram_send_message(f'Total time of training: {timeProceed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took so long to train on one epoch: [62, 68, 47, 48, 57] minutes\n"
     ]
    }
   ],
   "source": [
    "plotTimesPerEpoch(callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Acc: 0.7750169836956522\n",
      " Test Acc: 0.7761548913043478\n"
     ]
    }
   ],
   "source": [
    "calAccImageModel(model, val_seq, 'Val', GLOBAL_BATCH_SIZE)\n",
    "calAccImageModel(model, test_seq, 'Test', GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "telegram_send_message(f'-----------------DONE-----------------')\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
