{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from time import time, gmtime, strftime\n",
    "\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "from utils.models.modelUtils import loadMeanFromFile, calcAccConcatModel\n",
    "\n",
    "from final_models import create_text_model, create_model_meta, buildConcatModelTitleMeta\n",
    "\n",
    "from utils.callbacks.MyCallbacks import MyCallbacks\n",
    "from utils.datagenUtils.dual_modal.DataSeqTitleMeta import DataSequenceTitleMeta\n",
    "from utils.datagenUtils.datagenUtils import checkDataframe\n",
    "\n",
    "from utils.telegramUtils.telegram_bot import telegram_send_message\n",
    "from utils.textUtils.commentsProcessing import FakeDetectionDataCommentsTest, FakeDetectionDataCommentsTrainVal\n",
    "\n",
    "from utils.callbacks.callbackUtils import plotTimesPerEpoch\n",
    "\n",
    "from utils.fileDirUtils.fileDirUtils import createDirIfNotExists\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Batch Size: 4096, Epochs: 20, Optimizer: Adam, Learning Rate; 1e-05, Beta_1: 0.9, Beta_2: 0.999, Epsilon: 1e-08, BERT Max sequence length: 128\n"
     ]
    }
   ],
   "source": [
    "#Verbose settings:\n",
    "verbose = False\n",
    "TF_VERBOSE = 1 # 1 = Progress bar 2 = one line per epoch only!\n",
    "TF_DETERMINISTIC_OPS = 1 # Makes everything also on GPU deterministic\n",
    "\n",
    "# Classes:\n",
    "NUM_CLASS = 2  # FAKE | NO FAKE\n",
    "\n",
    "# Hyperparameters\n",
    "GLOBAL_BATCH_SIZE = 4096\n",
    "EPOCHS = 20\n",
    "\n",
    "# Optimizer parameters:\n",
    "# Adam\n",
    "LEARNING_RATE = 1e-5\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "#optimizers:\n",
    "\n",
    "optimizer = Adam(LEARNING_RATE, BETA_1, BETA_2, EPSILON)\n",
    "\n",
    "# Bert Parameters\n",
    "MAX_SEQUENCE_LENGTH = 128 # from model definition!\n",
    "\n",
    "# Training switches\n",
    "RETRAIN_WHOLE_MODEL = False\n",
    "loadPretrained = False # Attention that model weights path is set !\n",
    "\n",
    "# Custom telegram send text \n",
    "CUSTOM_TEXT = f'Batch Size: {GLOBAL_BATCH_SIZE}, Epochs: {EPOCHS}, Optimizer: Adam, Learning Rate; {LEARNING_RATE}, Beta_1: {BETA_1}, Beta_2: {BETA_2}, Epsilon: {EPSILON}, BERT Max sequence length: {MAX_SEQUENCE_LENGTH}'\n",
    "\n",
    "\n",
    "telegram_send_message(f'-----------------START-----------------')\n",
    "print('START')\n",
    "print(CUSTOM_TEXT)\n",
    "telegram_send_message(CUSTOM_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToRootModelDir = '/home/armin/repos/fkd-model-handling/models/best_models'\n",
    "\n",
    "pathToBertModelTitle = os.path.join(pathToRootModelDir, 'single_text_title', 'weights-improvement-02-0.88.hdf5')\n",
    "pathToMetaModel = os.path.join(pathToRootModelDir, 'single_meta', 'weights-improvement-100-0.62.hdf5')\n",
    "\n",
    "pathToCSVWithFileNamesAndLabelsTrain = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/train_text_image_meta_label.csv'\n",
    "\n",
    "pathToCSVWithFileNamesAndLabelsVal = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/val_text_image_meta_label.csv'\n",
    "\n",
    "pathToCSVWithFileNamesAndLabelsTest = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/test_text_image_meta_label.csv'\n",
    "\n",
    "checkpointDir = '/home/armin/repos/FKD-Dataset/011_checkpoints'\n",
    "\n",
    "ModelCommentseMetaWeightsPath = \"\"\n",
    "\n",
    "root = '/home/armin/repos/fkd-model-handling/'\n",
    "bert_model_dir = os.path.join(root, 'multi_cased_L-12_H-768_A-12')\n",
    "bert_config_file = os.path.join(bert_model_dir, \"bert_config.json\")\n",
    "bert_ckpt_file = os.path.join(bert_model_dir, \"bert_model.ckpt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other ettings\n",
    "\n",
    "# Time settings:\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "#Checkpoint settings:\n",
    "checkpoint_name = \"model_concat_comments_meta\"\n",
    "\n",
    "checkpointDir = os.path.join(checkpointDir, (checkpoint_name + '_' + current_time))\n",
    "\n",
    "fileName=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filePath = os.path.join(checkpointDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/tensorboard does not exist, creating it instead!\n"
     ]
    }
   ],
   "source": [
    "# Callback Handling:\n",
    "tensorboardDir = os.path.join(checkpointDir, 'tensorboard')\n",
    "\n",
    "createDirIfNotExists(tensorboardDir)\n",
    "createDirIfNotExists(checkpointDir)\n",
    "\n",
    "\n",
    "callbacks_list = MyCallbacks(tensorboardDir, filePath, earlyStopping=True).createCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Needed to remove 3566 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 1628 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 1610 elements to make it matching from dataframe\n"
     ]
    }
   ],
   "source": [
    "df_train_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsTrain, header=0, sep='\\t')\n",
    "df_test_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsTest, header=0, sep='\\t')\n",
    "df_val_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsVal, header=0, sep='\\t')\n",
    "\n",
    "df_train_['2_way_label'] = df_train_['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_test_['2_way_label'] = df_test_['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_val_['2_way_label'] = df_val_['2_way_label'].apply(lambda x: np.array(x))\n",
    "\n",
    "df_train = df_train_\n",
    "df_test = df_test_\n",
    "df_val = df_val_\n",
    "\n",
    "# df_train = df_train[:8000]\n",
    "# df_test = df_test[:8000]\n",
    "# df_val = df_val[:8000]\n",
    "\n",
    "df_train = checkDataframe(df_train, GLOBAL_BATCH_SIZE)\n",
    "df_val = checkDataframe(df_val, GLOBAL_BATCH_SIZE)\n",
    "df_test = checkDataframe(df_test, GLOBAL_BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "557056it [31:40, 293.08it/s]\n",
      "57344it [03:20, 286.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 55475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57344it [03:23, 281.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 39424\n"
     ]
    }
   ],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_model_dir, \"vocab.txt\"))\n",
    "\n",
    "all_comments_data = FakeDetectionDataCommentsTrainVal(df_train, df_val, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "all_comments_data_test = FakeDetectionDataCommentsTest(df_test, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "train_comments_x = all_comments_data.train_x\n",
    "train_comments_val_x = all_comments_data.val_x\n",
    "test_comments_x = all_comments_data_test.test_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = DataSequenceTitleMeta(df_train, train_comments_x, GLOBAL_BATCH_SIZE)\n",
    "\n",
    "test_seq = DataSequenceTitleMeta(df_test,  test_comments_x, GLOBAL_BATCH_SIZE)\n",
    "\n",
    "val_seq = DataSequenceTitleMeta(df_val,  train_comments_val_x, GLOBAL_BATCH_SIZE)\n",
    "\n",
    "STEP_SIZE_TRAIN = len(df_train) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_TEST = len(df_test) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_VAL = len(df_val) // GLOBAL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Concatenate, Dense, Dropout, GlobalAveragePooling2D, Input, Lambda\n",
    "# def buildConcatModelTitleMeta(model_bert_title, model_meta, NUM_CLASS):\n",
    "#     model_bert_title_output = model_bert_title.get_layer('bert_output_layer_768').output\n",
    "#     model_meta_output = model_meta.get_layer('final_output').output\n",
    "    \n",
    "#     # Build new models, without softmax\n",
    "#     model_bert_title = Model(model_bert_title.inputs, model_bert_title_output)    \n",
    "#     model_meta = Model(model_meta.inputs, model_meta_output)\n",
    "    \n",
    "#     x = Dense(128, activation = 'relu')(model_bert_title.output)\n",
    "#     x = Dense (32, activation = 'relu')(x)\n",
    "#     x = Dense (6, activation = 'relu')(x)\n",
    "#     concatenate = Concatenate()([model_bert_title.output, x]) # Fusion\n",
    "#     x = Dense(12, activation = 'relu')(concatenate)\n",
    "#     x = Dropout(0.4)(x)\n",
    "#     output = Dense(NUM_CLASS, activation='softmax', name='final_multimodal_output')(x)\n",
    "#     model_concat = Model([model_bert_title.input, model_meta.input], output)\n",
    "#     return model_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "bert shape (None, 128, 768)\n",
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.6222INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57047, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-01-0.65.hdf5\n",
      "136/136 [==============================] - 1174s 9s/step - loss: 0.6239 - accuracy: 0.6222 - val_loss: 0.5705 - val_accuracy: 0.6510 - lr: 1.0000e-05\n",
      "Epoch 2/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.6641\n",
      "Epoch 00002: val_loss improved from 0.57047 to 0.54416, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-02-0.76.hdf5\n",
      "136/136 [==============================] - 1180s 9s/step - loss: 0.5884 - accuracy: 0.6641 - val_loss: 0.5442 - val_accuracy: 0.7634 - lr: 1.0000e-05\n",
      "Epoch 3/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5729 - accuracy: 0.6846\n",
      "Epoch 00003: val_loss improved from 0.54416 to 0.52971, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-03-0.77.hdf5\n",
      "136/136 [==============================] - 1179s 9s/step - loss: 0.5729 - accuracy: 0.6846 - val_loss: 0.5297 - val_accuracy: 0.7673 - lr: 1.0000e-05\n",
      "Epoch 4/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.6859\n",
      "Epoch 00004: val_loss improved from 0.52971 to 0.52216, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-04-0.77.hdf5\n",
      "136/136 [==============================] - 1181s 9s/step - loss: 0.5661 - accuracy: 0.6859 - val_loss: 0.5222 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
      "Epoch 5/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5608 - accuracy: 0.6870\n",
      "Epoch 00005: val_loss improved from 0.52216 to 0.51530, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-05-0.77.hdf5\n",
      "136/136 [==============================] - 1181s 9s/step - loss: 0.5608 - accuracy: 0.6870 - val_loss: 0.5153 - val_accuracy: 0.7690 - lr: 1.0000e-05\n",
      "Epoch 6/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5570 - accuracy: 0.6879\n",
      "Epoch 00006: val_loss improved from 0.51530 to 0.50939, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-06-0.77.hdf5\n",
      "136/136 [==============================] - 1184s 9s/step - loss: 0.5570 - accuracy: 0.6879 - val_loss: 0.5094 - val_accuracy: 0.7699 - lr: 1.0000e-05\n",
      "Epoch 7/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5516 - accuracy: 0.6918\n",
      "Epoch 00007: val_loss improved from 0.50939 to 0.50455, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-07-0.77.hdf5\n",
      "136/136 [==============================] - 1184s 9s/step - loss: 0.5516 - accuracy: 0.6918 - val_loss: 0.5046 - val_accuracy: 0.7705 - lr: 1.0000e-05\n",
      "Epoch 8/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.6939\n",
      "Epoch 00008: val_loss improved from 0.50455 to 0.50029, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-08-0.77.hdf5\n",
      "136/136 [==============================] - 1182s 9s/step - loss: 0.5482 - accuracy: 0.6939 - val_loss: 0.5003 - val_accuracy: 0.7709 - lr: 1.0000e-05\n",
      "Epoch 9/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.6955\n",
      "Epoch 00009: val_loss improved from 0.50029 to 0.49640, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-09-0.77.hdf5\n",
      "136/136 [==============================] - 1183s 9s/step - loss: 0.5459 - accuracy: 0.6955 - val_loss: 0.4964 - val_accuracy: 0.7727 - lr: 1.0000e-05\n",
      "Epoch 10/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.6981\n",
      "Epoch 00010: val_loss improved from 0.49640 to 0.49114, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-10-0.78.hdf5\n",
      "136/136 [==============================] - 1181s 9s/step - loss: 0.5427 - accuracy: 0.6981 - val_loss: 0.4911 - val_accuracy: 0.7819 - lr: 1.0000e-05\n",
      "Epoch 11/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.7244\n",
      "Epoch 00011: val_loss improved from 0.49114 to 0.48519, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-11-0.79.hdf5\n",
      "136/136 [==============================] - 1181s 9s/step - loss: 0.5380 - accuracy: 0.7244 - val_loss: 0.4852 - val_accuracy: 0.7886 - lr: 1.0000e-05\n",
      "Epoch 12/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.7297\n",
      "Epoch 00012: val_loss improved from 0.48519 to 0.48084, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-12-0.79.hdf5\n",
      "136/136 [==============================] - 1182s 9s/step - loss: 0.5351 - accuracy: 0.7297 - val_loss: 0.4808 - val_accuracy: 0.7942 - lr: 1.0000e-05\n",
      "Epoch 13/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.7320\n",
      "Epoch 00013: val_loss improved from 0.48084 to 0.47784, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-13-0.80.hdf5\n",
      "136/136 [==============================] - 1182s 9s/step - loss: 0.5327 - accuracy: 0.7320 - val_loss: 0.4778 - val_accuracy: 0.7958 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.7341\n",
      "Epoch 00014: val_loss improved from 0.47784 to 0.47483, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-14-0.80.hdf5\n",
      "136/136 [==============================] - 1181s 9s/step - loss: 0.5305 - accuracy: 0.7341 - val_loss: 0.4748 - val_accuracy: 0.7971 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.7362\n",
      "Epoch 00015: val_loss improved from 0.47483 to 0.47262, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-15-0.80.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 1183s 9s/step - loss: 0.5284 - accuracy: 0.7362 - val_loss: 0.4726 - val_accuracy: 0.7983 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.7366\n",
      "Epoch 00016: val_loss improved from 0.47262 to 0.46981, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-16-0.80.hdf5\n",
      "136/136 [==============================] - 1182s 9s/step - loss: 0.5271 - accuracy: 0.7366 - val_loss: 0.4698 - val_accuracy: 0.7998 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.7380\n",
      "Epoch 00017: val_loss improved from 0.46981 to 0.46887, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-17-0.80.hdf5\n",
      "136/136 [==============================] - 1182s 9s/step - loss: 0.5248 - accuracy: 0.7380 - val_loss: 0.4689 - val_accuracy: 0.8007 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.7382\n",
      "Epoch 00018: val_loss improved from 0.46887 to 0.46611, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-18-0.80.hdf5\n",
      "136/136 [==============================] - 1180s 9s/step - loss: 0.5245 - accuracy: 0.7382 - val_loss: 0.4661 - val_accuracy: 0.8022 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.7399\n",
      "Epoch 00019: val_loss improved from 0.46611 to 0.46493, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-19-0.80.hdf5\n",
      "136/136 [==============================] - 1181s 9s/step - loss: 0.5234 - accuracy: 0.7399 - val_loss: 0.4649 - val_accuracy: 0.8024 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "136/136 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.7419\n",
      "Epoch 00020: val_loss improved from 0.46493 to 0.46292, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-20-0.80.hdf5\n",
      "136/136 [==============================] - 1181s 9s/step - loss: 0.5214 - accuracy: 0.7419 - val_loss: 0.4629 - val_accuracy: 0.8034 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    # Preparing:\n",
    "    model_bert_comments, model_bert_comments_custom_layer = create_text_model(max_seq_len=MAX_SEQUENCE_LENGTH, bert_ckpt_file=bert_ckpt_file, bert_config_file= bert_config_file,NUM_CLASS=NUM_CLASS, overwriteLayerAndEmbeddingSize=False, isPreTrained=True,  pathToBertModelWeights=pathToBertModelTitle, isTrainable=RETRAIN_WHOLE_MODEL)\n",
    "    model_meta, model_meta_custom_layer = create_model_meta(NUM_CLASS, 2, True, pathToMetaModel, isTrainable=RETRAIN_WHOLE_MODEL)\n",
    "    \n",
    "    model_concat = buildConcatModelTitleMeta(model_bert_comments, model_meta, 2)\n",
    "    \n",
    "    if loadPretrained:\n",
    "        model_concat.load_weights(ModelCommentseMetaWeightsPath)\n",
    "\n",
    "    if verbose:\n",
    "        print('--------------Text Title MODEL --------------')\n",
    "        model_bert_comments.summary()\n",
    "        print('-------------- Meta MODEL --------------')\n",
    "        model_meta.summary()\n",
    "        print('--------------CONCAT MODEL --------------')\n",
    "        model_concat.summary()\n",
    "        for l in model_concat.layers:\n",
    "            print(l.name, l.trainable)\n",
    "    \n",
    "    \n",
    "    model_concat.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    history = model_concat.fit(train_seq,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,epochs=EPOCHS, \n",
    "                    validation_data=val_seq,\n",
    "                    validation_steps=STEP_SIZE_VAL, \n",
    "                    callbacks=callbacks_list,\n",
    "                    use_multiprocessing=False,\n",
    "                    verbose=TF_VERBOSE,\n",
    "                    workers=12\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "plot_model(model_concat, to_file=os.path.join(checkpointDir,'multiple_inputs_image_text_meta_pretrained.png'), show_shapes=True, dpi=600, expand_nested=False)\n",
    "plot_model(model_concat, to_file=os.path.join(checkpointDir,'multiple_inputs_image_text_meta_pretrained_nested.png'), show_shapes=True, dpi=600, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For later model loading\n",
    "modelFile = '/home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_comments_meta_2020-07-20_11:39/weights-improvement-10-0.78.hdf5'\n",
    "\n",
    "model_concat.load_weights(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took so long to train on one epoch: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20] minutes\n"
     ]
    }
   ],
   "source": [
    "plotTimesPerEpoch(callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 92s 7s/step\n",
      "Val Accuracy is 0.7819126674107143\n",
      "14/14 [==============================] - 92s 7s/step\n",
      "Test Accuracy is 0.7816510881696429\n"
     ]
    }
   ],
   "source": [
    "calcAccConcatModel(model_concat, val_seq, GLOBAL_BATCH_SIZE, 'Val')\n",
    "calcAccConcatModel(model_concat, test_seq, GLOBAL_BATCH_SIZE, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "telegram_send_message(f'-----------------DONE-----------------')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
