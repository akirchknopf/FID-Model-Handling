{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training textual modality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from time import time, gmtime, strftime\n",
    "\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "from utils.models.modelUtils import calcAccTextModel\n",
    "\n",
    "from final_models import create_text_model\n",
    "\n",
    "from utils.callbacks.MyCallbacks import MyCallbacks\n",
    "\n",
    "from utils.telegramUtils.telegram_bot import telegram_send_message\n",
    "from utils.textUtils.commentsProcessing import FakeDetectionDataCommentsTest, FakeDetectionDataCommentsTrainVal\n",
    "\n",
    "from utils.callbacks.callbackUtils import plotTimesPerEpoch\n",
    "\n",
    "from utils.fileDirUtils.fileDirUtils import createDirIfNotExists\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verbose settings:\n",
    "verbose = False\n",
    "TF_VERBOSE = 1 # 1 = Progress bar 2 = one line per epoch only!\n",
    "TF_DETERMINISTIC_OPS = 1 # Makes everything also on GPU deterministic\n",
    "\n",
    "# Classes:\n",
    "NUM_CLASS = 2  # FAKE | NO FAKE\n",
    "\n",
    "# Hyperparameters\n",
    "GLOBAL_BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "# Optimizer parameters:\n",
    "# Adam\n",
    "LEARNING_RATE = 1e-5\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "#optimizers:\n",
    "\n",
    "optimizer = Adam(LEARNING_RATE)\n",
    "\n",
    "# Bert Parameters\n",
    "MAX_SEQUENCE_LENGTH = 32 \n",
    "\n",
    "# Custom telegram send text \n",
    "CUSTOM_TEXT = f'Batch Size: {GLOBAL_BATCH_SIZE}, Epochs: {EPOCHS}, Optimizer: Adam, Learning Rate; {LEARNING_RATE}, Beta_1: {BETA_1}, Beta_2: {BETA_2}, Epsilon: {EPSILON}, BERT Max sequence length: {MAX_SEQUENCE_LENGTH}'\n",
    "\n",
    "\n",
    "telegram_send_message(f'-----------------START-----------------')\n",
    "print('START')\n",
    "print(CUSTOM_TEXT)\n",
    "telegram_send_message(CUSTOM_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "root = '/home/armin/repos/fkd-model-handling/'\n",
    "\n",
    "bert_model_dir = os.path.join(root, 'multi_cased_L-12_H-768_A-12')\n",
    "pathToBertVocabFile = os.path.join(bert_model_dir, \"vocab.txt\")\n",
    "bert_ckpt_file = os.path.join(bert_model_dir, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_model_dir, \"bert_config.json\")\n",
    "\n",
    "pathToTextLabelFiles = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/'\n",
    "\n",
    "trainTextFile = os.path.join(pathToTextLabelFiles, \"train_text_image_meta_label.csv\")\n",
    "testTextFile = os.path.join(pathToTextLabelFiles, \"test_text_image_meta_label.csv\")\n",
    "valTextFile = os.path.join(pathToTextLabelFiles, \"val_text_image_meta_label.csv\")\n",
    "\n",
    "checkpointDir = '/home/armin/repos/FKD-Dataset/011_checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings:\n",
    "\n",
    "# Time settings:\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "#Checkpoint settings:\n",
    "checkpoint_name = f'bert_only_{MAX_SEQUENCE_LENGTH}'\n",
    "\n",
    "checkpointDir = os.path.join(checkpointDir, (checkpoint_name + '_' + current_time))\n",
    "\n",
    "fileName=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filePath = os.path.join(checkpointDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(trainTextFile, header=0, sep='\\t')\n",
    "df_test = pd.read_csv(testTextFile, header=0, sep='\\t')\n",
    "df_val = pd.read_csv(valTextFile, header=0, sep='\\t')\n",
    "\n",
    "# df_train = df_train[:1024]\n",
    "# df_test = df_test[:1024]\n",
    "# df_val = df_val[:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating BERT compatible data:\n",
    "\n",
    "tokenizer = FullTokenizer(vocab_file=pathToBertVocabFile)\n",
    "text_data_train = FakeDetectionDataCommentsTrainVal(df_train, df_val, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "text_data_test = FakeDetectionDataCommentsTest(df_test, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback Handling:\n",
    "tensorboardDir = os.path.join(checkpointDir, 'tensorboard')\n",
    "\n",
    "createDirIfNotExists(tensorboardDir)\n",
    "createDirIfNotExists(checkpointDir)\n",
    "\n",
    "\n",
    "callbacks_list = MyCallbacks(tensorboardDir, filePath, earlyStopping=True).createCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_send_message(f'Starting with Text Model, checkpoints can be found in {checkpointDir} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    model = create_text_model(MAX_SEQUENCE_LENGTH, bert_ckpt_file, bert_config_file, NUM_CLASS) \n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "      text_data_train.train_x, text_data_train.train_y,\n",
    "      validation_data = (text_data_train.val_x, text_data_train.val_y),\n",
    "      callbacks=callbacks_list,\n",
    "      batch_size=GLOBAL_BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      verbose = TF_VERBOSE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time()\n",
    "timeProceed = (end - start) / 60\n",
    "print(f'It took {timeProceed} minutes to train everything' )\n",
    "telegram_send_message(f'Total time of training: {timeProceed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTimesPerEpoch(callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcAccTextModel(model, text_data_train.val_x, text_data_train.val_y, 'Val', GLOBAL_BATCH_SIZE)\n",
    "calcAccTextModel(model, text_data_test.test_x, text_data_test.test_y, 'Test', GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_send_message(f'-----------------DONE-----------------')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
