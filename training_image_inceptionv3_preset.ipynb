{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Training visual modality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from time import time, gmtime, strftime\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from utils.textUtils.textpreprocessing import FakeDetectionDataTest, FakeDetectionDataTrainVal\n",
    "\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "from final_models import create_image_inceptionv3_model\n",
    "\n",
    "from utils.callbacks.MyCallbacks import MyCallbacks\n",
    "\n",
    "from utils.datagenUtils.DataSeqThreeModels import DataSequenceThreeModels\n",
    "\n",
    "from utils.telegramUtils.telegram_bot import telegram_send_message\n",
    "\n",
    "from utils.textUtils.textpreprocessing import FakeDetectionDataTrainVal, FakeDetectionDataTest\n",
    "\n",
    "from utils.callbacks.callbackUtils import plotTimesPerEpoch\n",
    "\n",
    "from utils.fileDirUtils.fileDirUtils import createDirIfNotExists\n",
    "\n",
    "from utils.models.modelUtils import checkDataframe, loadMeanFromFile, calAccImageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Batch Size: 256, Epochs: 10, Optimizer: Adam, Learning Rate; 1e-05, Beta_1: 0.9, Beta_2: 0.999, Epsilon: 1e-08\n"
     ]
    }
   ],
   "source": [
    "#Verbose settings:\n",
    "verbose = False\n",
    "TF_VERBOSE = 1 # 1 = Progress bar 2 = one line per epoch only!\n",
    "TF_DETERMINISTIC_OPS = 1 # Makes everything also on GPU deterministic\n",
    "\n",
    "# Classes:\n",
    "NUM_CLASS = 2  # FAKE | NO FAKE\n",
    "\n",
    "# Hyperparameters\n",
    "GLOBAL_BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "\n",
    "# Optimizer parameters:\n",
    "# Adam\n",
    "LEARNING_RATE = 1e-5\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "#optimizers:\n",
    "\n",
    "optimizer = Adam(LEARNING_RATE)\n",
    "\n",
    "# Image Model  Parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_DEPTH = 3\n",
    "IMG_SIZES = (IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "# Custom telegram send text \n",
    "CUSTOM_TEXT = f'Batch Size: {GLOBAL_BATCH_SIZE}, Epochs: {EPOCHS}, Optimizer: Adam, Learning Rate; {LEARNING_RATE}, Beta_1: {BETA_1}, Beta_2: {BETA_2}, Epsilon: {EPSILON}'\n",
    "\n",
    "\n",
    "telegram_send_message(f'-----------------START-----------------')\n",
    "print('START')\n",
    "print(CUSTOM_TEXT)\n",
    "telegram_send_message(CUSTOM_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "root = '/home/armin/repos/fkd-model-handling/'\n",
    "\n",
    "pathToImagesTrain = '/home/armin/repos/FKD-Dataset/006_Bilder_Resized/train/' \n",
    "pathToCSVWithFileNamesAndLabelsTrain = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/train_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesVal = '/home/armin/repos/FKD-Dataset/006_Bilder_Resized/val/' \n",
    "pathToCSVWithFileNamesAndLabelsVal = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/val_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesTest = '/home/armin/repos/FKD-Dataset/006_Bilder_Resized/test/' \n",
    "pathToCSVWithFileNamesAndLabelsTest = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/test_text_image_meta_label.csv'\n",
    "\n",
    "pathToMeans = '/home/armin/repos/FKD-Dataset/010_configs/means_resized.txt'\n",
    "\n",
    "checkpointDir = '/home/armin/repos/FKD-Dataset/011_checkpoints'\n",
    "\n",
    "bert_model_dir = os.path.join(root, 'multi_cased_L-12_H-768_A-12')\n",
    "bert_ckpt_file = os.path.join(bert_model_dir, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_model_dir, \"bert_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other ettings\n",
    "\n",
    "# Time settings:\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "#Checkpoint settings:\n",
    "checkpoint_name = \"InceptionV3\"\n",
    "\n",
    "checkpointDir = os.path.join(checkpointDir, (checkpoint_name + '_' + current_time))\n",
    "\n",
    "fileName=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filePath = os.path.join(checkpointDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Needed to remove 238 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 74 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 92 elements to make it matching from dataframe\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "df_train = pd.read_csv(pathToCSVWithFileNamesAndLabelsTrain, header=0, sep='\\t')\n",
    "df_test = pd.read_csv(pathToCSVWithFileNamesAndLabelsTest, header=0, sep='\\t')\n",
    "df_val = pd.read_csv(pathToCSVWithFileNamesAndLabelsVal, header=0, sep='\\t')\n",
    "\n",
    "df_train['2_way_label'] = df_train['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_test['2_way_label'] = df_test['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_val['2_way_label'] = df_val['2_way_label'].apply(lambda x: np.array(x))\n",
    "\n",
    "# df_train = df_train[:512]\n",
    "# df_test = df_test[:512]\n",
    "# df_val = df_val[:512]\n",
    "\n",
    "df_train = checkDataframe(df_train, GLOBAL_BATCH_SIZE)\n",
    "df_test = checkDataframe(df_test, GLOBAL_BATCH_SIZE)       \n",
    "df_val = checkDataframe(df_val, GLOBAL_BATCH_SIZE)   \n",
    "\n",
    "STEP_SIZE_TRAIN = len(df_train) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_TEST = len(df_test) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_VAL = len(df_val) // GLOBAL_BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/armin/repos/FKD-Dataset/011_checkpoints/InceptionV3_2020-07-10_11:58/tensorboard does not exist, creating it instead!\n"
     ]
    }
   ],
   "source": [
    "# Callback Handling:\n",
    "tensorboardDir = os.path.join(checkpointDir, 'tensorboard')\n",
    "\n",
    "createDirIfNotExists(tensorboardDir)\n",
    "createDirIfNotExists(checkpointDir)\n",
    "\n",
    "\n",
    "callbacks_list = MyCallbacks(tensorboardDir, filePath, earlyStopping=True).createCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansOfDataset = loadMeanFromFile(pathToMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560384it [02:16, 4091.31it/s]\n",
      "58880it [00:14, 4165.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58880it [00:14, 4135.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 512\n"
     ]
    }
   ],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_model_dir, \"vocab.txt\"))\n",
    "\n",
    "all_text_data = FakeDetectionDataTrainVal(df_train, df_val, tokenizer, [0,1])\n",
    "\n",
    "max_seq_len = all_text_data.max_seq_len\n",
    "\n",
    "all_text_test = FakeDetectionDataTest(df_test, tokenizer, [0,1], max_seq_len)\n",
    "\n",
    "train_x = all_text_data.train_x\n",
    "val_x = all_text_data.val_x\n",
    "test_x = all_text_test.test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = DataSequenceThreeModels(df_train, pathToImagesTrain, train_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "test_seq = DataSequenceThreeModels(df_test, pathToImagesTest, test_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "val_seq = DataSequenceThreeModels(df_val, pathToImagesVal,  val_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 192 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 192 all-reduces with algorithm = nccl, num_packs = 1\n",
      "2189/2189 [==============================] - ETA: 0s - accuracy: 0.7387 - loss: 0.5082\n",
      "Epoch 00001: val_loss improved from inf to 0.45792, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/InceptionV3_2020-07-10_11:58/weights-improvement-01-0.77.hdf5\n",
      "2189/2189 [==============================] - 3769s 2s/step - accuracy: 0.7387 - loss: 0.5082 - val_accuracy: 0.7724 - val_loss: 0.4579 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "2189/2189 [==============================] - ETA: 0s - accuracy: 0.8005 - loss: 0.4157\n",
      "Epoch 00002: val_loss improved from 0.45792 to 0.44816, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/InceptionV3_2020-07-10_11:58/weights-improvement-02-0.78.hdf5\n",
      "2189/2189 [==============================] - 3697s 2s/step - accuracy: 0.8005 - loss: 0.4157 - val_accuracy: 0.7810 - val_loss: 0.4482 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "2189/2189 [==============================] - ETA: 0s - accuracy: 0.8495 - loss: 0.3326\n",
      "Epoch 00003: val_loss did not improve from 0.44816\n",
      "2189/2189 [==============================] - 2243s 1s/step - accuracy: 0.8495 - loss: 0.3326 - val_accuracy: 0.7769 - val_loss: 0.4926 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "2189/2189 [==============================] - ETA: 0s - accuracy: 0.9119 - loss: 0.2142\n",
      "Epoch 00004: val_loss did not improve from 0.44816\n",
      "2189/2189 [==============================] - 2138s 977ms/step - accuracy: 0.9119 - loss: 0.2142 - val_accuracy: 0.7661 - val_loss: 0.6055 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "2189/2189 [==============================] - ETA: 0s - accuracy: 0.9692 - loss: 0.0878\n",
      "Epoch 00005: val_loss did not improve from 0.44816\n",
      "Restoring model weights from the end of the best epoch.\n",
      "2189/2189 [==============================] - 2146s 980ms/step - accuracy: 0.9692 - loss: 0.0878 - val_accuracy: 0.7580 - val_loss: 0.9894 - lr: 1.0000e-05\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    model = create_image_inceptionv3_model(NUM_CLASS)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_seq,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        epochs=EPOCHS, \n",
    "                        validation_data=val_seq,\n",
    "                        validation_steps=STEP_SIZE_VAL,\n",
    "                        callbacks=callbacks_list,\n",
    "                        verbose = TF_VERBOSE\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 234.4251169204712 minutes to train everything\n"
     ]
    }
   ],
   "source": [
    "end = time()\n",
    "timeProceed = (end - start) / 60\n",
    "print(f'It took {timeProceed} minutes to train everything' )\n",
    "telegram_send_message(f'Total time of training: {timeProceed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took so long to train on one epoch: [64, 62, 37, 36, 36] minutes\n"
     ]
    }
   ],
   "source": [
    "plotTimesPerEpoch(callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Acc: 0.7811141304347826\n",
      " Test Acc: 0.7847826086956522\n"
     ]
    }
   ],
   "source": [
    "calAccImageModel(model, val_seq, 'Val', GLOBAL_BATCH_SIZE)\n",
    "calAccImageModel(model, test_seq, 'Test', GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "telegram_send_message(f'-----------------DONE-----------------')\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
