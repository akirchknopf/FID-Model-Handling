{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Training visual modality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from time import time, gmtime, strftime\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from utils.textUtils.textpreprocessing import FakeDetectionDataTest, FakeDetectionDataTrainVal\n",
    "\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "from final_models import create_image_resnet50v2_model\n",
    "\n",
    "from utils.callbacks.MyCallbacks import MyCallbacks\n",
    "\n",
    "from utils.datagenUtils.DataSeqThreeModels import DataSequenceThreeModels\n",
    "\n",
    "from utils.telegramUtils.telegram_bot import telegram_send_message\n",
    "\n",
    "from utils.textUtils.textpreprocessing import FakeDetectionDataTrainVal, FakeDetectionDataTest\n",
    "\n",
    "from utils.callbacks.callbackUtils import plotTimesPerEpoch\n",
    "\n",
    "from utils.fileDirUtils.fileDirUtils import createDirIfNotExists\n",
    "\n",
    "from utils.models.modelUtils import checkDataframe, loadMeanFromFile, calAccImageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Batch Size: 32, Epochs: 10, Optimizer: Adam, Learning Rate; 1e-05, Beta_1: 0.9, Beta_2: 0.999, Epsilon: 1e-08\n"
     ]
    }
   ],
   "source": [
    "#Verbose settings:\n",
    "verbose = False\n",
    "TF_VERBOSE = 1 # 1 = Progress bar 2 = one line per epoch only!\n",
    "TF_DETERMINISTIC_OPS = 1 # Makes everything also on GPU deterministic\n",
    "\n",
    "# Classes:\n",
    "NUM_CLASS = 2  # FAKE | NO FAKE\n",
    "\n",
    "# Hyperparameters\n",
    "GLOBAL_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Optimizer parameters:\n",
    "# Adam\n",
    "LEARNING_RATE = 1e-5\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "#optimizers:\n",
    "\n",
    "optimizer = Adam(LEARNING_RATE, BETA_1, BETA_2, EPSILON)\n",
    "\n",
    "\n",
    "# Image Model  Parameters\n",
    "IMG_WIDTH = 768\n",
    "IMG_HEIGHT = 768\n",
    "IMG_DEPTH = 3\n",
    "IMG_SIZES = (IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "RETRAIN_TOP_ONLY = False\n",
    "\n",
    "# Custom telegram send text \n",
    "CUSTOM_TEXT = f'Batch Size: {GLOBAL_BATCH_SIZE}, Epochs: {EPOCHS}, Optimizer: Adam, Learning Rate; {LEARNING_RATE}, Beta_1: {BETA_1}, Beta_2: {BETA_2}, Epsilon: {EPSILON}'\n",
    "\n",
    "\n",
    "telegram_send_message(f'-----------------START-----------------')\n",
    "print('START')\n",
    "print(CUSTOM_TEXT)\n",
    "telegram_send_message(CUSTOM_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "root = '/home/armin/repos/fkd-model-handling/'\n",
    "\n",
    "pathToImagesTrain = '/home/armin/repos/FKD-Dataset/002_images/train/' \n",
    "pathToCSVWithFileNamesAndLabelsTrain = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/train_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesVal = '/home/armin/repos/FKD-Dataset/002_images/val/' \n",
    "pathToCSVWithFileNamesAndLabelsVal = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/val_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesTest = '/home/armin/repos/FKD-Dataset/002_images/test/' \n",
    "pathToCSVWithFileNamesAndLabelsTest = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/test_text_image_meta_label.csv'\n",
    "\n",
    "pathToMeans = '/home/armin/repos/FKD-Dataset/010_configs/means_resized.txt'\n",
    "\n",
    "checkpointDir = '/home/armin/repos/FKD-Dataset/011_checkpoints'\n",
    "\n",
    "bert_model_dir = os.path.join(root, 'multi_cased_L-12_H-768_A-12')\n",
    "bert_ckpt_file = os.path.join(bert_model_dir, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_model_dir, \"bert_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other ettings\n",
    "\n",
    "# Time settings:\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "#Checkpoint settings:\n",
    "checkpoint_name = \"ResNet50V2\"\n",
    "\n",
    "checkpointDir = os.path.join(checkpointDir, (checkpoint_name + '_' + current_time))\n",
    "\n",
    "fileName=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filePath = os.path.join(checkpointDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Needed to remove 14 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 10 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 28 elements to make it matching from dataframe\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "df_train = pd.read_csv(pathToCSVWithFileNamesAndLabelsTrain, header=0, sep='\\t')\n",
    "df_test = pd.read_csv(pathToCSVWithFileNamesAndLabelsTest, header=0, sep='\\t')\n",
    "df_val = pd.read_csv(pathToCSVWithFileNamesAndLabelsVal, header=0, sep='\\t')\n",
    "\n",
    "df_train['2_way_label'] = df_train['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_test['2_way_label'] = df_test['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_val['2_way_label'] = df_val['2_way_label'].apply(lambda x: np.array(x))\n",
    "\n",
    "# df_train = df_train[:512]\n",
    "# df_test = df_test[:512]\n",
    "# df_val = df_val[:512]\n",
    "\n",
    "df_train = checkDataframe(df_train, GLOBAL_BATCH_SIZE)\n",
    "df_test = checkDataframe(df_test, GLOBAL_BATCH_SIZE)       \n",
    "df_val = checkDataframe(df_val, GLOBAL_BATCH_SIZE)   \n",
    "\n",
    "STEP_SIZE_TRAIN = len(df_train) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_TEST = len(df_test) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_VAL = len(df_val) // GLOBAL_BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/armin/repos/FKD-Dataset/011_checkpoints/ResNet50V2_2020-07-11_15:23/tensorboard does not exist, creating it instead!\n"
     ]
    }
   ],
   "source": [
    "# Callback Handling:\n",
    "tensorboardDir = os.path.join(checkpointDir, 'tensorboard')\n",
    "\n",
    "createDirIfNotExists(tensorboardDir)\n",
    "createDirIfNotExists(checkpointDir)\n",
    "\n",
    "\n",
    "callbacks_list = MyCallbacks(tensorboardDir, filePath, earlyStopping=True).createCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansOfDataset = loadMeanFromFile(pathToMeans, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560608it [02:10, 4309.11it/s]\n",
      "58944it [00:13, 4361.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58944it [00:13, 4337.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq_len 512\n"
     ]
    }
   ],
   "source": [
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_model_dir, \"vocab.txt\"))\n",
    "\n",
    "all_text_data = FakeDetectionDataTrainVal(df_train, df_val, tokenizer, [0,1])\n",
    "\n",
    "max_seq_len = all_text_data.max_seq_len\n",
    "\n",
    "all_text_test = FakeDetectionDataTest(df_test, tokenizer, [0,1], max_seq_len)\n",
    "\n",
    "train_x = all_text_data.train_x\n",
    "val_x = all_text_data.val_x\n",
    "test_x = all_text_test.test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = DataSequenceThreeModels(df_train, pathToImagesTrain, train_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "test_seq = DataSequenceThreeModels(df_test, pathToImagesTest, test_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "val_seq = DataSequenceThreeModels(df_val, pathToImagesVal,  val_x, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input , Lambda\n",
    "from tensorflow.keras import Model\n",
    "def create_image_resnet50v2_model1(NUM_CLASS, isPreTrained=False, pathToResNet50V2ModelWeights=None):\n",
    "    resnet50v2 = ResNet50V2(weights='imagenet', include_top=False)\n",
    "    last_layer = resnet50v2.output\n",
    "    x = GlobalAveragePooling2D()(last_layer)\n",
    "    x = Dense(768, activation='relu', name='img_dense_768')(x)\n",
    "    out = Dense(NUM_CLASS, activation='softmax', name='img_output_layer')(x)\n",
    "    resnet50v2 = Model(inputs=resnet50v2.input, outputs=out, name=\"ResNet50V2\")\n",
    "    \n",
    "    if not isPreTrained:\n",
    "        return resnet50v2              \n",
    "    else:\n",
    "        resnet50v2.load_weights(pathToResNet50V2ModelWeights)\n",
    "        return resnet50v2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1\n",
      "17519/17519 [==============================] - ETA: 0s - loss: 0.4694 - accuracy: 0.7627\n",
      "Epoch 00001: val_loss improved from inf to 0.42093, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/ResNet50V2_2020-07-11_15:23/weights-improvement-01-0.80.hdf5\n",
      "17519/17519 [==============================] - 16616s 948ms/step - loss: 0.4694 - accuracy: 0.7627 - val_loss: 0.4209 - val_accuracy: 0.7951 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "17519/17519 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.8229\n",
      "Epoch 00002: val_loss improved from 0.42093 to 0.40568, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/ResNet50V2_2020-07-11_15:23/weights-improvement-02-0.81.hdf5\n",
      "17519/17519 [==============================] - 16438s 938ms/step - loss: 0.3748 - accuracy: 0.8229 - val_loss: 0.4057 - val_accuracy: 0.8081 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "17519/17519 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.8859\n",
      "Epoch 00003: val_loss did not improve from 0.40568\n",
      "17519/17519 [==============================] - 16242s 927ms/step - loss: 0.2613 - accuracy: 0.8859 - val_loss: 0.4720 - val_accuracy: 0.7916 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "17519/17519 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9502\n",
      "Epoch 00004: val_loss did not improve from 0.40568\n",
      "17519/17519 [==============================] - 15122s 863ms/step - loss: 0.1259 - accuracy: 0.9502 - val_loss: 0.6700 - val_accuracy: 0.7934 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "17519/17519 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9739\n",
      "Epoch 00005: val_loss did not improve from 0.40568\n",
      "Restoring model weights from the end of the best epoch.\n",
      "17519/17519 [==============================] - 15008s 857ms/step - loss: 0.0688 - accuracy: 0.9739 - val_loss: 0.8937 - val_accuracy: 0.7825 - lr: 1.0000e-05\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    model = create_image_resnet50v2_model1(NUM_CLASS)\n",
    "\n",
    "    if RETRAIN_TOP_ONLY:\n",
    "        for layer in model.layers[:-2]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "    if verbose:\n",
    "        for l in model.layers:\n",
    "            print(l.name, l.trainable)\n",
    "        model.summary()\n",
    "    \n",
    "\n",
    "\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_seq,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        epochs=EPOCHS, \n",
    "                        validation_data=val_seq,\n",
    "                        validation_steps=STEP_SIZE_VAL,\n",
    "                        callbacks=callbacks_list,\n",
    "                        verbose = TF_VERBOSE\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 1325.0550244847934 minutes to train everything\n"
     ]
    }
   ],
   "source": [
    "end = time()\n",
    "timeProceed = (end - start) / 60\n",
    "print(f'It took {timeProceed} minutes to train everything' )\n",
    "telegram_send_message(f'Total time of training: {timeProceed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took so long to train on one epoch: [278, 274, 271, 252, 250] minutes\n"
     ]
    }
   ],
   "source": [
    "plotTimesPerEpoch(callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Acc: 0.8089203311617806\n",
      " Test Acc: 0.8129241313789359\n"
     ]
    }
   ],
   "source": [
    "calAccImageModel(model, val_seq, 'Val', GLOBAL_BATCH_SIZE)\n",
    "calAccImageModel(model, test_seq, 'Test', GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "telegram_send_message(f'-----------------DONE-----------------')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
