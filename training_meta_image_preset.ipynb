{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from time import time, gmtime, strftime\n",
    "\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "\n",
    "from utils.models.modelUtils import loadMeanFromFile, calcAccConcatModel\n",
    "from final_models import create_image_inceptionv3_model, create_model_meta, buildConcatModelMetaVisual\n",
    "\n",
    "from utils.callbacks.MyCallbacks import MyCallbacks\n",
    "from utils.datagenUtils.dual_modal.DataSeqMetaVisual import DataSequenceMetaImage\n",
    "\n",
    "from utils.datagenUtils.datagenUtils import checkDataframe\n",
    "\n",
    "from utils.telegramUtils.telegram_bot import telegram_send_message\n",
    "from utils.textUtils.commentsProcessing import FakeDetectionDataCommentsTest, FakeDetectionDataCommentsTrainVal\n",
    "\n",
    "from utils.callbacks.callbackUtils import plotTimesPerEpoch\n",
    "\n",
    "from utils.fileDirUtils.fileDirUtils import createDirIfNotExists\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Batch Size: 128, Epochs: 10, Optimizer: Adam, Learning Rate; 1e-05, Beta_1: 0.9, Beta_2: 0.999, Epsilon: 1e-08, Image Sizes: (768, 768)\n"
     ]
    }
   ],
   "source": [
    "#Verbose settings:\n",
    "verbose = False\n",
    "TF_VERBOSE = 1 # 1 = Progress bar 2 = one line per epoch only!\n",
    "TF_DETERMINISTIC_OPS = 1 # Makes everything also on GPU deterministic\n",
    "\n",
    "# Classes:\n",
    "NUM_CLASS = 2  # FAKE | NO FAKE\n",
    "\n",
    "# Hyperparameters\n",
    "GLOBAL_BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "# Optimizer parameters:\n",
    "# Adam\n",
    "LEARNING_RATE = 1e-5\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "#optimizers:\n",
    "\n",
    "optimizer = Adam(LEARNING_RATE, BETA_1, BETA_2, EPSILON)\n",
    "\n",
    "\n",
    "# Image Model  Parameters\n",
    "IMG_WIDTH = 768\n",
    "IMG_HEIGHT = 768\n",
    "IMG_DEPTH = 3\n",
    "IMG_SIZES = (IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "# Retraining options\n",
    "RETRAIN_WHOLE_MODEL = False\n",
    "loadPretrained = False # If true model weights path must be set !\n",
    "\n",
    "# Custom telegram send text \n",
    "CUSTOM_TEXT = f'Batch Size: {GLOBAL_BATCH_SIZE}, Epochs: {EPOCHS}, Optimizer: Adam, Learning Rate; {LEARNING_RATE}, Beta_1: {BETA_1}, Beta_2: {BETA_2}, Epsilon: {EPSILON}, Image Sizes: {IMG_SIZES}'\n",
    "\n",
    "\n",
    "telegram_send_message(f'-----------------START-----------------')\n",
    "print('START')\n",
    "print(CUSTOM_TEXT)\n",
    "telegram_send_message(CUSTOM_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToRootModelDir = '/home/armin/repos/fkd-model-handling/models/best_models'\n",
    "\n",
    "pathToImageModel = os.path.join(pathToRootModelDir, 'single_visual', 'weights-improvement-02-0.81.hdf5')\n",
    "pathToMetaModel = os.path.join(pathToRootModelDir, 'single_meta', 'weights-improvement-100-0.62.hdf5')\n",
    "\n",
    "pathToImagesTrain = '/home/armin/repos/FKD-Dataset/006_images_resized_2/train/' \n",
    "pathToCSVWithFileNamesAndLabelsTrain = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/train_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesVal = '/home/armin/repos/FKD-Dataset/006_images_resized_2/val/' \n",
    "pathToCSVWithFileNamesAndLabelsVal = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/val_text_image_meta_label.csv'\n",
    "\n",
    "pathToImagesTest = '/home/armin/repos/FKD-Dataset/006_images_resized_2/test/' \n",
    "pathToCSVWithFileNamesAndLabelsTest = '/home/armin/repos/FKD-Dataset/008_text_image_meta_label/test_text_image_meta_label.csv'\n",
    "\n",
    "pathToMeans = '/home/armin/repos/FKD-Dataset/010_configs/means_resized_768.txt'\n",
    "\n",
    "pathToModelWeights = ''\n",
    "\n",
    "checkpointDir = '/home/armin/repos/FKD-Dataset/011_checkpoints'\n",
    "\n",
    "root = '/home/armin/repos/fkd-model-handling/'\n",
    "bert_model_dir = os.path.join(root, 'multi_cased_L-12_H-768_A-12')\n",
    "bert_config_file = os.path.join(bert_model_dir, \"bert_config.json\")\n",
    "bert_ckpt_file = os.path.join(bert_model_dir, \"bert_model.ckpt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other ettings\n",
    "\n",
    "# Time settings:\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "#Checkpoint settings:\n",
    "checkpoint_name = \"model_concat_meta_image\"\n",
    "\n",
    "checkpointDir = os.path.join(checkpointDir, (checkpoint_name + '_' + current_time))\n",
    "\n",
    "fileName=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filePath = os.path.join(checkpointDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_meta_image_2020-07-20_20:41/tensorboard does not exist, creating it instead!\n"
     ]
    }
   ],
   "source": [
    "# Callback Handling:\n",
    "tensorboardDir = os.path.join(checkpointDir, 'tensorboard')\n",
    "\n",
    "createDirIfNotExists(tensorboardDir)\n",
    "createDirIfNotExists(checkpointDir)\n",
    "\n",
    "\n",
    "callbacks_list = MyCallbacks(tensorboardDir, filePath, earlyStopping=True).createCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Needed to remove 110 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 92 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 74 elements to make it matching from dataframe\n"
     ]
    }
   ],
   "source": [
    "df_train_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsTrain, header=0, sep='\\t')\n",
    "df_test_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsTest, header=0, sep='\\t')\n",
    "df_val_ = pd.read_csv(pathToCSVWithFileNamesAndLabelsVal, header=0, sep='\\t')\n",
    "\n",
    "df_train_['2_way_label'] = df_train_['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_test_['2_way_label'] = df_test_['2_way_label'].apply(lambda x: np.array(x))\n",
    "df_val_['2_way_label'] = df_val_['2_way_label'].apply(lambda x: np.array(x))\n",
    "\n",
    "df_train = df_train_\n",
    "df_test = df_test_\n",
    "df_val = df_val_\n",
    "\n",
    "# df_train = df_train[:8000]\n",
    "# df_test = df_test[:8000]\n",
    "# df_val = df_val[:8000]\n",
    "\n",
    "df_train = checkDataframe(df_train, GLOBAL_BATCH_SIZE)\n",
    "df_val = checkDataframe(df_val, GLOBAL_BATCH_SIZE)\n",
    "df_test = checkDataframe(df_test, GLOBAL_BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = FullTokenizer(vocab_file=os.path.join(bert_model_dir, \"vocab.txt\"))\n",
    "\n",
    "\n",
    "# all_text_data = FakeDetectionDataCommentsTrainVal(df_train, df_val, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "# all_text_test = FakeDetectionDataCommentsTest(df_test, tokenizer, [0,1], MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "# train_x = all_text_data.train_x\n",
    "# val_x = all_text_data.val_x\n",
    "# test_x = all_text_test.test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meansOfDataset = loadMeanFromFile(pathToMeans, verbose)\n",
    "\n",
    "train_seq = DataSequenceMetaImage(df_train, pathToImagesTrain, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "test_seq = DataSequenceMetaImage(df_test, pathToImagesTest, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "val_seq = DataSequenceMetaImage(df_val, pathToImagesVal, GLOBAL_BATCH_SIZE, IMG_SIZES, meansOfDataset)\n",
    "\n",
    "STEP_SIZE_TRAIN = len(df_train) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_TEST = len(df_test) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_VAL = len(df_val) // GLOBAL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def buildConcatModelMetaVisual(model_meta, model_image, NUM_CLASS):\n",
    "#     model_meta_output = model_meta.get_layer('final_output').output\n",
    "#     model_image_output = model_image.get_layer('img_dense_768').output\n",
    "    \n",
    "#     # Build new models, without softmax\n",
    "#     model_image = Model(model_image.inputs, model_image_output)    \n",
    "#     model_meta = Model(model_meta.inputs, model_meta_output)\n",
    "    \n",
    "#     x = Dense(128, activation = 'relu')(model_image.output)\n",
    "#     x = Dense (32, activation = 'relu')(x)\n",
    "#     x = Dense (6, activation = 'relu')(x)\n",
    "#     concatenate = Concatenate()([model_meta.output, x]) # Fusion\n",
    "#     x = Dense(12, activation = 'relu')(concatenate)\n",
    "#     x = Dropout(0.4)(x)\n",
    "#     output = Dense(NUM_CLASS, activation='softmax', name='final_multimodal_output')(x)\n",
    "#     model_concat = Model([model_image.input, model_meta.input], output)\n",
    "#     return model_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "4379/4379 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.7947\n",
      "Epoch 00001: val_loss improved from inf to 0.39375, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_meta_image_2020-07-20_20:41/weights-improvement-01-0.81.hdf5\n",
      "4379/4379 [==============================] - 5150s 1s/step - loss: 0.4136 - accuracy: 0.7947 - val_loss: 0.3938 - val_accuracy: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "4379/4379 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.8201\n",
      "Epoch 00002: val_loss did not improve from 0.39375\n",
      "4379/4379 [==============================] - 5162s 1s/step - loss: 0.3728 - accuracy: 0.8201 - val_loss: 0.3938 - val_accuracy: 0.8132 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "4379/4379 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.8335\n",
      "Epoch 00003: val_loss did not improve from 0.39375\n",
      "4379/4379 [==============================] - 5188s 1s/step - loss: 0.3678 - accuracy: 0.8335 - val_loss: 0.3949 - val_accuracy: 0.8137 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "4379/4379 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8344\n",
      "Epoch 00004: val_loss did not improve from 0.39375\n",
      "Restoring model weights from the end of the best epoch.\n",
      "4379/4379 [==============================] - 5160s 1s/step - loss: 0.3659 - accuracy: 0.8344 - val_loss: 0.3957 - val_accuracy: 0.8138 - lr: 1.0000e-05\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    # Preparing:\n",
    "    model_image, model_image_custom_layer = create_image_inceptionv3_model(NUM_CLASS=NUM_CLASS,isPreTrained=True,pathToInceptionV3ModelWeights=pathToImageModel, isTrainable=RETRAIN_WHOLE_MODEL)\n",
    "    model_meta, model_meta_custom_layer = create_model_meta(NUM_CLASS, 2, True, pathToMetaModel, isTrainable=RETRAIN_WHOLE_MODEL)\n",
    "    \n",
    "    model_concat = buildConcatModelMetaVisual(model_meta, model_image, NUM_CLASS)\n",
    "\n",
    "    if verbose:\n",
    "        print('--------------IMAGE MODEL --------------')\n",
    "        model_image.summary()\n",
    "        print('--------------Meta MODEL --------------')\n",
    "        model_meta.summary()\n",
    "        print('--------------CONCAT MODEL --------------')\n",
    "        model_concat.summary()\n",
    "        for l in model_concat.layers:\n",
    "            print(l.name, l.trainable)\n",
    "            \n",
    "    if loadPretrained:\n",
    "        model_concat.load_weights(pathToModelWeights)\n",
    "    \n",
    "    \n",
    "    model_concat.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "          optimizer=optimizer,\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    history = model_concat.fit(train_seq,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,epochs=EPOCHS, \n",
    "                    validation_data=val_seq,\n",
    "                    validation_steps=STEP_SIZE_VAL, \n",
    "                    callbacks=callbacks_list,\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=12,\n",
    "                    verbose=TF_VERBOSE\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For later model loading\n",
    "# modelFile = '/home/armin/repos/FKD-Dataset/011_checkpoints/model_concat_title_image_2020-07-15_13:16/weights-improvement-02-0.91.hdf5'\n",
    "\n",
    "# model_concat.load_weights(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "plot_model(model_concat, to_file=os.path.join(checkpointDir,'multiple_inputs_image_text_meta_pretrained.png'), show_shapes=True, dpi=600, expand_nested=False)\n",
    "plot_model(model_concat, to_file=os.path.join(checkpointDir,'multiple_inputs_image_text_meta_pretrained_nested.png'), show_shapes=True, dpi=600, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/460 [==============================] - 1301s 3s/step\n",
      "Val Accuracy is 0.8122112771739131\n",
      "460/460 [==============================] - 1350s 3s/step\n",
      "Test Accuracy is 0.815625\n",
      "It took so long to train on one epoch: [86, 86, 87, 86] minutes\n"
     ]
    }
   ],
   "source": [
    "plotTimesPerEpoch(callbacks_list)\n",
    "calcAccConcatModel(model_concat, val_seq, GLOBAL_BATCH_SIZE, 'Val')\n",
    "calcAccConcatModel(model_concat, test_seq, GLOBAL_BATCH_SIZE, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "telegram_send_message(f'-----------------DONE-----------------')\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
