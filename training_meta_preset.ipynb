{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training meta only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from time import time, gmtime, strftime\n",
    "\n",
    "from final_models import create_model_meta\n",
    "\n",
    "from utils.models.modelUtils import calcAccMetaModel\n",
    "\n",
    "from utils.datagenUtils.datagenUtils import checkDataframe, convertRowToDictionary\n",
    "\n",
    "from utils.datagenUtils.DataSeqMetaModel import DataSequenceMetaModel\n",
    "\n",
    "from utils.callbacks.MyCallbacks import MyCallbacks\n",
    "\n",
    "from utils.telegramUtils.telegram_bot import telegram_send_message\n",
    "\n",
    "from utils.callbacks.callbackUtils import plotTimesPerEpoch\n",
    "\n",
    "from utils.fileDirUtils.fileDirUtils import createDirIfNotExists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Batch Size: 1024, Epochs: 100, Optimizer: Adam, Learning Rate; 1e-05, Beta_1: 0.9, Beta_2: 0.999, Epsilon: 1e-08\n"
     ]
    }
   ],
   "source": [
    "#Verbose settings:\n",
    "verbose = False\n",
    "\n",
    "TF_VERBOSE = 1 # 1 = Progress bar 2 = one line per epoch only!\n",
    "TF_DETERMINISTIC_OPS = 1 # Makes everything also on GPU deterministic\n",
    "\n",
    "# Classes:\n",
    "NUM_CLASS = 2  # FAKE | NO FAKE\n",
    "\n",
    "# Optimizer parameters:\n",
    "# Adam\n",
    "LEARNING_RATE = 1e-5\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "#optimizers:\n",
    "\n",
    "optimizer = Adam(LEARNING_RATE, BETA_1, BETA_2, EPSILON)\n",
    "\n",
    "# Network Settings:\n",
    "\n",
    "#for training the whole model\n",
    "GLOBAL_BATCH_SIZE = 1024 # 16 for all three\n",
    "EPOCHS = 100\n",
    "\n",
    "# Custom telegram send text \n",
    "CUSTOM_TEXT = f'Batch Size: {GLOBAL_BATCH_SIZE}, Epochs: {EPOCHS}, Optimizer: Adam, Learning Rate; {LEARNING_RATE}, Beta_1: {BETA_1}, Beta_2: {BETA_2}, Epsilon: {EPSILON}'\n",
    "\n",
    "\n",
    "telegram_send_message(f'-----------------START-----------------')\n",
    "print('START')\n",
    "print(CUSTOM_TEXT)\n",
    "telegram_send_message(CUSTOM_TEXT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToTextLabelFiles = '/home/armin/repos/FKD-Dataset/009_meta_label'\n",
    "\n",
    "trainTextFile = os.path.join(pathToTextLabelFiles, \"train_meta_label.csv\")\n",
    "testTextFile = os.path.join(pathToTextLabelFiles, \"test_meta_label.csv\")\n",
    "valTextFile = os.path.join(pathToTextLabelFiles, \"val_meta_label.csv\")\n",
    "\n",
    "\n",
    "df_train_whole = pd.read_csv(trainTextFile, header=0, sep='\\t')\n",
    "df_test_whole = pd.read_csv(testTextFile, header=0, sep='\\t')\n",
    "df_val_whole = pd.read_csv(valTextFile, header=0, sep='\\t')\n",
    "\n",
    "checkpointDir = '/home/armin/repos/FKD-Dataset/011_checkpoints/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings:\n",
    "\n",
    "# Time settings:\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "#Checkpoint settings:\n",
    "checkpoint_name = f'meta_only'\n",
    "\n",
    "checkpointDir = os.path.join(checkpointDir, (checkpoint_name + '_' + current_time))\n",
    "\n",
    "fileName=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filePath = os.path.join(checkpointDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #backup original dataseq\n",
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from numpy import asarray\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# class DataSequenceMetaModel(Sequence):\n",
    "#     'Generates data for Keras'\n",
    "#     def __init__(self, df, batch_size):\n",
    "#         self.df = df\n",
    "#         self.batch_size = batch_size\n",
    "#         self.on_epoch_end()\n",
    "        \n",
    "#         len_of_df = np.array(len(self.df))\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "#         return int(np.floor(len(self.df) / self.batch_size))\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "#         # Generate indexes of the batch\n",
    "#         batch_indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "#         # Slice df\n",
    "#         df_batch = self.df.take(batch_indices)\n",
    "\n",
    "#         # Generate data\n",
    "#         meta_x, global_y = self.__data_generation(df_batch, batch_indices)\n",
    "\n",
    "#         return [meta_x], global_y\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch -> Resetting them' \n",
    "#         self.indices = np.arange(len(self.df))\n",
    "        \n",
    "#     def get_image(self, path, img_size):\n",
    "#         return load_img(path, target_size=[img_size[0], img_size[1]])\n",
    "\n",
    "#     def __data_generation(self, df_slice, batch_indices):\n",
    "#         batch_x = []\n",
    "#         batch_y = []\n",
    "\n",
    "#         for index, rowRaw in enumerate(df_slice.itertuples(), 1):\n",
    "#             row = convertRowToDictionary(rowRaw, df_slice.columns, True)\n",
    "#             batch_x.append([ row['author_enc'], row['score'], row['hasNanScore'], row['upvote_ratio'], row['hasNanUpvote'] , row['num_comments']])\n",
    "# #             batch_x.append([row['author_enc'], row['score'], row['hasNanScore'], row['upvote_ratio'], row['hasNanUpvote'], row['num_comments']])\n",
    "#             batch_y.append([row['2_way_label']])\n",
    "#         meta_x = np.array(batch_x)\n",
    "#         global_y = np.array(batch_y).astype(np.float32)\n",
    "        \n",
    "        \n",
    "\n",
    "#         return (meta_x, global_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Needed to remove 494 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 586 elements to make it matching from dataframe\n",
      "Warning: Needed to remove 604 elements to make it matching from dataframe\n"
     ]
    }
   ],
   "source": [
    "df_train_whole = checkDataframe(df_train_whole, GLOBAL_BATCH_SIZE)\n",
    "df_test_whole = checkDataframe(df_test_whole, GLOBAL_BATCH_SIZE)\n",
    "df_val_whole = checkDataframe(df_val_whole, GLOBAL_BATCH_SIZE)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_whole = DataSequenceMetaModel(df_train_whole, GLOBAL_BATCH_SIZE)\n",
    "test_seq_whole = DataSequenceMetaModel(df_test_whole, GLOBAL_BATCH_SIZE)\n",
    "val_seq_whole = DataSequenceMetaModel(df_val_whole, GLOBAL_BATCH_SIZE)\n",
    "\n",
    "STEP_SIZE_TRAIN = len(df_train_whole) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_TEST = len(df_test_whole) // GLOBAL_BATCH_SIZE\n",
    "STEP_SIZE_VAL = len(df_val_whole) // GLOBAL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboardDir = os.path.join(checkpointDir, 'tensorboard')\n",
    "callbacks_list = MyCallbacks(tensorboardDir, filePath, earlyStopping=True).createCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "545/547 [============================>.] - ETA: 0s - accuracy: 0.0000e+00 - loss: 8105.4053INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5496.37061, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/meta_only_2020-07-14_07:55/weights-improvement-01-0.00.hdf5\n",
      "547/547 [==============================] - 14s 26ms/step - accuracy: 0.0000e+00 - loss: 8095.4058 - val_accuracy: 0.0000e+00 - val_loss: 5496.3706 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "543/547 [============================>.] - ETA: 0s - accuracy: 0.3842 - loss: 1508.2909\n",
      "Epoch 00002: val_loss improved from 5496.37061 to 0.71605, saving model to /home/armin/repos/FKD-Dataset/011_checkpoints/meta_only_2020-07-14_07:55/weights-improvement-02-0.92.hdf5\n",
      "547/547 [==============================] - 14s 26ms/step - accuracy: 0.3850 - loss: 1497.2699 - val_accuracy: 0.9244 - val_loss: 0.7160 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "544/547 [============================>.] - ETA: 0s - accuracy: 0.6333 - loss: 0.8814\n",
      "Epoch 00003: val_loss did not improve from 0.71605\n",
      "547/547 [==============================] - 14s 25ms/step - accuracy: 0.6332 - loss: 0.8818 - val_accuracy: 0.9518 - val_loss: 0.9438 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "545/547 [============================>.] - ETA: 0s - accuracy: 0.6244 - loss: 0.8782\n",
      "Epoch 00004: val_loss did not improve from 0.71605\n",
      "547/547 [==============================] - 14s 26ms/step - accuracy: 0.6240 - loss: 0.8774 - val_accuracy: 0.9400 - val_loss: 0.8384 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "546/547 [============================>.] - ETA: 0s - accuracy: 0.6173 - loss: 1.1248\n",
      "Epoch 00005: val_loss did not improve from 0.71605\n",
      "Restoring model weights from the end of the best epoch.\n",
      "547/547 [==============================] - 14s 25ms/step - accuracy: 0.6179 - loss: 1.1248 - val_accuracy: 0.0347 - val_loss: 1.5829 - lr: 1.0000e-05\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    model = create_model_meta(NUM_CLASS, 6) \n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_seq_whole,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN, epochs=EPOCHS, \n",
    "                    validation_data=val_seq_whole,\n",
    "                    validation_steps=STEP_SIZE_VAL,  \n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose = TF_VERBOSE\n",
    "                   )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took so long to train on one epoch: [0, 0, 0, 0, 0] minutes\n"
     ]
    }
   ],
   "source": [
    "plotTimesPerEpoch(callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy is 0.6116193804824561\n",
      "Test Accuracy is 0.6119620339912281\n"
     ]
    }
   ],
   "source": [
    "calcAccMetaModel(model, val_seq_whole, GLOBAL_BATCH_SIZE, 'Val')\n",
    "calcAccMetaModel(model, test_seq_whole, GLOBAL_BATCH_SIZE, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "telegram_send_message(f'-----------------DONE-----------------')\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
